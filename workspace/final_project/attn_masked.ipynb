{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c41cff-8b49-4811-8813-250cec29b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d42f73ae-3f50-49eb-8b2d-92eade8d97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    matrix_size_M_dim=2048,\n",
    "    matrix_size_K_dim=2048,\n",
    "    matrix_size_N_dim=2048,\n",
    "    \n",
    "    DRAM_factor_M=1024,\n",
    "    DRAM_factor_N=2048,\n",
    "    DRAM_factor_K=2048,\n",
    "    DRAM_permutation=['K', 'N', 'M'],\n",
    "    \n",
    "    ClusterArray_factor_M=2,\n",
    "    ClusterArray_factor_N=1,\n",
    "    ClusterArray_factor_K=1,\n",
    "    ClusterArray_permutation=['K', 'N', 'M'],\n",
    "    \n",
    "    GLB_Cluster_factor_M=1,\n",
    "    GLB_Cluster_factor_N=1,\n",
    "    GLB_Cluster_factor_K=1,\n",
    "    GLB_Cluster_permutation=['K', 'N', 'M'],\n",
    "\n",
    "    glb_factor_M=1, \n",
    "    glb_factor_N=1, \n",
    "    glb_factor_K=1, \n",
    "    glb_permutation=['K', 'N', 'M'],\n",
    "\n",
    "    PE_Cluster_factor_M=1,\n",
    "    PE_Cluster_factor_N=1,\n",
    "    PE_Cluster_factor_K=1,\n",
    "    PE_Cluster_permutation=['K', 'N', 'M'],\n",
    "\n",
    "    iact_spad_factor_M=1,\n",
    "    iact_spad_factor_N=1,\n",
    "    iact_spad_factor_K=1,\n",
    "    iact_spad_permutation=['K', 'N', 'M'],\n",
    "\n",
    "    weight_spad_factor_M=1,\n",
    "    weight_spad_factor_N=1,\n",
    "    weight_spad_factor_K=1,\n",
    "    weight_spad_permutation=['K', 'N', 'M'],\n",
    "\n",
    "    psum_factor_M=1,\n",
    "    psum_factor_N=1,\n",
    "    psum_factor_K=1,\n",
    "    psum_permutation=['K', 'N', 'M'],\n",
    "\n",
    "    reg_factor_M=1,\n",
    "    reg_factor_N=1,\n",
    "    reg_factor_K=1,\n",
    "    reg_permutation=['K', 'N', 'M'],\n",
    "\n",
    "    density_weights=1, \n",
    "    density_inputs=1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb3125b9-1847-456e-bd0f-acfa16cdd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modeling lower triangular matrices: \n",
    "|--|--|\n",
    "|Q1|Q2|\n",
    "|--|--|\n",
    "|Q4|Q3|\n",
    "|__|__|\n",
    "\n",
    "Q2: all-zeroes -- input density = 0\n",
    "Q4: input density = 1 (actual values)\n",
    "Q1 & Q3: input density = 0.5\n",
    "'''\n",
    "\n",
    "q1_config, q2_config, q4_config = config.copy(), config.copy(), config.copy()\n",
    "q1_config['density_inputs'] = 0.5\n",
    "q2_config['density_inputs'] = 0\n",
    "q4_config['density_inputs'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "646ad398-6af4-4071-a6d0-6f4f1c8ce607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2025-04-29 17:39:01,903 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2025-04-29 17:39:05,590 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "\n\n========================================================================================================================\nTimeloop model failed with return code 134. Please check the output files in ./output_dir for more information. To debug, you can edit the file:\n\t./output_dir/parsed-processed-input.yaml\nand run \n\ttimeloop model ./output_dir/parsed-processed-input.yaml\nto see the error. If you're running the mapper and Timeloop can't find a vaild mapping, try setting 'diagnostics: true' in the mapper input specification.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/final_project/loaders.py:54\u001b[0m, in \u001b[0;36mrun_timeloop_model\u001b[0;34m(jinja_parse_data, alt_top, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./output_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/backend_calls.py:268\u001b[0m, in \u001b[0;36mcall_model\u001b[0;34m(specification, output_dir, environment, extra_input_files, dump_intermediate_to, log_to, extra_args, return_proc)\u001b[0m\n\u001b[1;32m    264\u001b[0m input_paths, output_dir \u001b[38;5;241m=\u001b[39m _pre_call(\n\u001b[1;32m    265\u001b[0m     specification, output_dir, extra_input_files, for_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    266\u001b[0m )\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeloop-model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdump_intermediate_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdump_intermediate_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfor_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/backend_calls.py:184\u001b[0m, in \u001b[0;36m_parse_output\u001b[0;34m(specification, output_dir, result, for_model)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(errmsg)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n\n========================================================================================================================\nTimeloop model failed with return code 134. Please check the output files in ./output_dir for more information. To debug, you can edit the file:\n\t./output_dir/parsed-processed-input.yaml\nand run \n\ttl model ./output_dir/parsed-processed-input.yaml\nto see the error. If you're running the mapper and Timeloop can't find a vaild mapping, try setting 'diagnostics: true' in the mapper input specification.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m q1_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output_dir/timeloop-model.stats.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(q1_stats)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m q2_out \u001b[38;5;241m=\u001b[39m \u001b[43mrun_timeloop_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq2_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesigns/attention/quadrant_problem.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesigns/baseline/baseline_mapping.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_optimizations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesigns/baseline/baseline_sparse_opt.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m q2_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output_dir/timeloop-model.stats.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     18\u001b[0m q4_out \u001b[38;5;241m=\u001b[39m run_timeloop_model(\n\u001b[1;32m     19\u001b[0m     q4_config,\n\u001b[1;32m     20\u001b[0m     problem\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesigns/attention/quadrant_problem.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m     mapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesigns/baseline/baseline_mapping.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m     sparse_optimizations\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesigns/baseline/baseline_sparse_opt.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m~/final_project/loaders.py:56\u001b[0m, in \u001b[0;36mrun_timeloop_model\u001b[0;34m(jinja_parse_data, alt_top, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tl\u001b[38;5;241m.\u001b[39mcall_model(spec, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtl model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeloop model\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mException\u001b[0m: \n\n========================================================================================================================\nTimeloop model failed with return code 134. Please check the output files in ./output_dir for more information. To debug, you can edit the file:\n\t./output_dir/parsed-processed-input.yaml\nand run \n\ttimeloop model ./output_dir/parsed-processed-input.yaml\nto see the error. If you're running the mapper and Timeloop can't find a vaild mapping, try setting 'diagnostics: true' in the mapper input specification."
     ]
    }
   ],
   "source": [
    "q1_out = run_timeloop_model(\n",
    "    q1_config,\n",
    "    problem='designs/attention/quadrant_problem.yaml',\n",
    "    mapping='designs/baseline/baseline_mapping.yaml',\n",
    "    sparse_optimizations='designs/baseline/baseline_sparse_opt.yaml', \n",
    ")\n",
    "q1_stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "# print(q1_stats)\n",
    "\n",
    "q2_out = run_timeloop_model(\n",
    "    q2_config,\n",
    "    problem='designs/attention/quadrant_problem.yaml',\n",
    "    mapping='designs/baseline/baseline_mapping.yaml',\n",
    "    sparse_optimizations='designs/baseline/baseline_sparse_opt.yaml', \n",
    ")\n",
    "q2_stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "\n",
    "q4_out = run_timeloop_model(\n",
    "    q4_config,\n",
    "    problem='designs/attention/quadrant_problem.yaml',\n",
    "    mapping='designs/baseline/baseline_mapping.yaml',\n",
    "    sparse_optimizations='designs/baseline/baseline_sparse_opt.yaml', \n",
    ")\n",
    "\n",
    "q4_stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fef38d8-10d1-4065-8292-c3ee922297f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running apps: model\n",
      "Found parsed-processed-input.yaml in input files. Running Timeloop without parsing or processing steps. If this is not the intended behavior, please name the input files differently.\n",
      "input file: /home/workspace/final_project/output_dir/parsed-processed-input.yaml\n",
      "execute:/usr/local/bin/accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml --oprefix timeloop-model. -o ./ > timeloop-model.accelergy.log 2>&1\n",
      "Warning: DRAM: adjust representation format word bits from 7 to 8 to avoid storage fragmentation.\n",
      "Warning: weight_spad: adjust representation format word bits from 7 to 8 to avoid storage fragmentation.\n",
      "WARNING: parsing mapping: permutation not found for level: glb (temporal)\n",
      "WARNING: parsing mapping: permutation contains insufficient dimensions at level: glb (temporal), padding with arbitrary order.\n",
      "WARNING: parsing mapping: factors not found for level: glb (temporal)\n",
      "WARNING: parsing mapping: factors not provided for all dimensions at level: glb (temporal), setting to 1.\n",
      "timeloop-model: src/sparse-analysis/compute-gs-analyzer.cpp:378: void sparse::CalculateFineGrainedComputeAccesses2Operand(const sparse::SparseAnalysisState&, tiling::CompoundTileNest&): Assertion `abs(skipped_compute + random_compute + gated_compute + nonexistent_compute - total_compute) < total_compute * 0.00001' failed.\n",
      "Aborted\n"
     ]
    }
   ],
   "source": [
    "!timeloop model ./output_dir/parsed-processed-input.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cbbd1e1-353e-43bc-81b2-c3d16cccd3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energy_per_compute_fJ': {'MAC': 15574.6,\n",
       "  'reg': 51.66,\n",
       "  'psum_spad': 574.69,\n",
       "  'weight_spad': 2036.82,\n",
       "  'iact_spad': 215.6,\n",
       "  'glb': 12124.79,\n",
       "  'DRAM': 192062.5,\n",
       "  'Total': 222640.65},\n",
       " 'total_energy_uJ': 956234.3,\n",
       " 'memory_energy_pJ': {'MAC': 66892397648.28,\n",
       "  'reg': 221861689.64,\n",
       "  'psum_spad': 2468241020.55,\n",
       "  'weight_spad': 8748023748.23,\n",
       "  'iact_spad': 925981205.12,\n",
       "  'glb': 34711410290.2,\n",
       "  'DRAM': 549755813888.0},\n",
       " 'memory_traffic': {'reg': 8589934592,\n",
       "  'psum_spad': 17175674880,\n",
       "  'weight_spad': 17179869184,\n",
       "  'iact_spad': 8589934592,\n",
       "  'glb': 25773998080,\n",
       "  'DRAM': 17184063488},\n",
       " 'utilization_percent': {'MAC': 1.0, 'overall': 0.06},\n",
       " 'computes_per_cycle': 1.0,\n",
       " 'actual_computes': 4294967296,\n",
       " 'cycles': 4294967296}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_timeloop_stats(content):\n",
    "    \n",
    "    results = {\n",
    "        'energy_per_compute_fJ': {},      # fJ/Compute per component\n",
    "        'total_energy_uJ': None,          # Total energy\n",
    "        'memory_energy_pJ': {},           # Total memory energy in pJ\n",
    "        'memory_traffic': {},             # Scalar accesses per memory level\n",
    "        'utilization_percent': {},        # Utilization per component and overall\n",
    "        'computes_per_cycle': None,       # Throughput\n",
    "        'actual_computes': None,          # Needed for later calc\n",
    "        'cycles': None                    # Needed for later calc\n",
    "    }\n",
    "\n",
    "    # 1. Energy per compute (fJ/Compute)\n",
    "    energy_compute_matches = re.findall(r\"fJ/Compute\\s+((?:.|\\n)+?)\\n\\n\", content)\n",
    "    if energy_compute_matches:\n",
    "        for line in energy_compute_matches[0].split('\\n'):\n",
    "            match = re.match(r\"\\s*(\\S+)\\s*=\\s*([\\d.]+)\", line)\n",
    "            if match:\n",
    "                component, value = match.groups()\n",
    "                results['energy_per_compute_fJ'][component] = float(value)\n",
    "\n",
    "    # 2. Total energy (Summary Stats)\n",
    "    total_energy_match = re.search(r\"Energy:\\s+([\\d.]+)\\s*uJ\", content)\n",
    "    if total_energy_match:\n",
    "        results['total_energy_uJ'] = float(total_energy_match.group(1))\n",
    "\n",
    "    # 3. Actual Computes and Cycles\n",
    "    actual_compute_match = re.search(r\"Actual Computes\\s*=\\s*(\\d+)\", content)\n",
    "    if actual_compute_match:\n",
    "        results['actual_computes'] = int(actual_compute_match.group(1))\n",
    "\n",
    "    cycle_match = re.search(r\"Cycles:\\s*(\\d+)\", content)\n",
    "    if cycle_match:\n",
    "        results['cycles'] = int(cycle_match.group(1))\n",
    "\n",
    "    if results['actual_computes'] and results['cycles']:\n",
    "        results['computes_per_cycle'] = results['actual_computes'] / results['cycles']\n",
    "\n",
    "    # 4. Memory traffic (scalar accesses per level)\n",
    "    memory_traffic_matches = re.findall(r\"=== (\\w+) ===\\n\\s*Total scalar accesses\\s*:\\s*(\\d+)\", content)\n",
    "    for level, accesses in memory_traffic_matches:\n",
    "        results['memory_traffic'][level] = int(accesses)\n",
    "\n",
    "    # 5. Memory energy: per component from `Energy (total)` lines\n",
    "    energy_total_matches = re.findall(r\"=== (\\w+) ===.+?Energy \\(total\\)\\s*:\\s*([\\d.]+)\\s*pJ\", content, re.DOTALL)\n",
    "    for level, energy in energy_total_matches:\n",
    "        results['memory_energy_pJ'][level] = float(energy)\n",
    "\n",
    "    # 6. Utilization (MAC unit + overall)\n",
    "    mac_util_match = re.search(r\"MAC.+?Utilized instances \\(average\\)\\s*:\\s*([\\d.]+)\", content, re.DOTALL)\n",
    "    if mac_util_match:\n",
    "        results['utilization_percent']['MAC'] = float(mac_util_match.group(1))\n",
    "\n",
    "    overall_util_match = re.search(r\"Utilization:\\s*([\\d.]+)%\", content)\n",
    "    if overall_util_match:\n",
    "        results['utilization_percent']['overall'] = float(overall_util_match.group(1))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "parse_timeloop_stats(q1_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9f65e38-e30f-4e47-bd1c-f1b4315b4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def aggregate_timeloop_runs(parsed_runs):\n",
    "    \n",
    "    aggregate = {\n",
    "        'total_energy_uJ': 0.0,\n",
    "        'memory_energy_pJ': defaultdict(float),\n",
    "        'memory_traffic': defaultdict(int),\n",
    "        'energy_per_compute_fJ': {},\n",
    "        'utilization_percent': {},\n",
    "        'computes_per_cycle': 0.0,\n",
    "    }\n",
    "\n",
    "    total_computes = 0\n",
    "    total_cycles = 0\n",
    "    fj_weighted_sums = defaultdict(float)\n",
    "    fj_total_computes = defaultdict(float)\n",
    "    utilization_weighted = defaultdict(float)\n",
    "    utilization_weights = defaultdict(float)\n",
    "\n",
    "    for run in parsed_runs:\n",
    "        # Sum total energy\n",
    "        aggregate['total_energy_uJ'] += run['total_energy_uJ']\n",
    "\n",
    "        # Sum memory energy\n",
    "        for level, energy in run['memory_energy_pJ'].items():\n",
    "            aggregate['memory_energy_pJ'][level] += energy\n",
    "\n",
    "        # Sum memory traffic\n",
    "        for level, accesses in run['memory_traffic'].items():\n",
    "            aggregate['memory_traffic'][level] += accesses\n",
    "\n",
    "        # fJ/Compute (weighted by actual computes)\n",
    "        computes = run['actual_computes']\n",
    "        for comp, fj in run['energy_per_compute_fJ'].items():\n",
    "            fj_weighted_sums[comp] += fj * computes\n",
    "            fj_total_computes[comp] += computes\n",
    "\n",
    "        # Utilization (weighted by cycles)\n",
    "        if run['cycles']:\n",
    "            for key, util in run['utilization_percent'].items():\n",
    "                utilization_weighted[key] += util * run['cycles']\n",
    "                utilization_weights[key] += run['cycles']\n",
    "\n",
    "        # Total actual computes and cycles for throughput\n",
    "        total_computes += computes\n",
    "        total_cycles += run['cycles']\n",
    "\n",
    "    # Finalize fJ/Compute\n",
    "    for comp in fj_weighted_sums:\n",
    "        aggregate['energy_per_compute_fJ'][comp] = fj_weighted_sums[comp] / fj_total_computes[comp]\n",
    "\n",
    "    # Finalize utilization\n",
    "    for key in utilization_weighted:\n",
    "        aggregate['utilization_percent'][key] = utilization_weighted[key] / utilization_weights[key]\n",
    "\n",
    "    # Finalize computes per cycle\n",
    "    if total_cycles > 0:\n",
    "        aggregate['computes_per_cycle'] = total_computes / total_cycles\n",
    "\n",
    "    # Attach raw totals (in case needed later)\n",
    "    aggregate['total_actual_computes'] = total_computes\n",
    "    aggregate['total_cycles'] = total_cycles\n",
    "\n",
    "    return aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c908271-f345-47a9-ba3b-d48ef02b72ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_energy_uJ': 3825666.6900000004,\n",
       " 'memory_energy_pJ': defaultdict(float,\n",
       "             {'MAC': 267703375394.77,\n",
       "              'reg': 887890481.93,\n",
       "              'psum_spad': 9877900564.310001,\n",
       "              'weight_spad': 34996098332.13,\n",
       "              'iact_spad': 3705776782.8900003,\n",
       "              'glb': 138845641160.8,\n",
       "              'DRAM': 2199023255552.0}),\n",
       " 'memory_traffic': defaultdict(int,\n",
       "             {'reg': 34376918237,\n",
       "              'psum_spad': 68702699520,\n",
       "              'weight_spad': 68719476736,\n",
       "              'iact_spad': 34376918237,\n",
       "              'glb': 103113172189,\n",
       "              'DRAM': 68736253952}),\n",
       " 'energy_per_compute_fJ': {'MAC': 15574.6,\n",
       "  'reg': 51.66,\n",
       "  'psum_spad': 574.69,\n",
       "  'weight_spad': 2036.0345113587853,\n",
       "  'iact_spad': 215.6,\n",
       "  'glb': 12120.749191202442,\n",
       "  'DRAM': 191998.5007522446,\n",
       "  'Total': 222571.82445480584},\n",
       " 'utilization_percent': {'MAC': 1.0, 'overall': 0.06},\n",
       " 'computes_per_cycle': 1.0,\n",
       " 'total_actual_computes': 17188459119,\n",
       " 'total_cycles': 17188459119}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats = [q1_stats, q2_stats, q1_stats, q4_stats]\n",
    "parsed_runs = [parse_timeloop_stats(stats) for stats in all_stats]\n",
    "\n",
    "combined_stats = aggregate_timeloop_runs(parsed_runs)\n",
    "\n",
    "combined_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b49c2-f63c-44cd-9b28-d4e48d04f15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
