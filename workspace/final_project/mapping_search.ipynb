{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f77928a-de22-48f2-8160-09ceaab41d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loaders import *\n",
    "import math\n",
    "import random\n",
    "from attn_masked import parse_timeloop_stats, aggregate_timeloop_runs\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335265f4-6e46-4548-a0dc-584caec31243",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = 2048 # CHANGE\n",
    "\n",
    "dataflow_permuations = [['M', 'N', 'K'], ['M', 'K', 'N'], ['N', 'K', 'M'], ['N', 'M', 'K'], ['K', 'N', 'M'], ['K', 'M', 'N']]\n",
    "'''\n",
    "6 different dataflow permutations\n",
    "9 components for dataflow\n",
    "= 6^9 = 10077696 possible combinations\n",
    "'''\n",
    "# generate all the data flow permuations\n",
    "def get_dataflow_permutations():\n",
    "    dataflow_perumations = []\n",
    "    \n",
    "    for DRAM in dataflow_permuations:\n",
    "        for ClusterArray in dataflow_permuations:\n",
    "            for GLB_Cluster in dataflow_permuations:\n",
    "                for glb in dataflow_permuations:\n",
    "                    for PE_Cluster in dataflow_permuations:\n",
    "                        for iact_spad in dataflow_permuations:\n",
    "                            for weight_spad in dataflow_permuations:\n",
    "                                for psum in dataflow_permuations:\n",
    "                                    for reg in dataflow_permuations:\n",
    "                                        permutation = {\n",
    "                                            \"DRAM\": DRAM,\n",
    "                                            \"ClusterArray\": ClusterArray,\n",
    "                                            # \"GLB_Cluster\": GLB_Cluster,\n",
    "                                            # \"glb\": glb,\n",
    "                                            \"PE_Cluster\": PE_Cluster,\n",
    "                                            \"iact_spad\": iact_spad,\n",
    "                                            \"weight_spad\": weight_spad,\n",
    "                                            \"psum\": psum,\n",
    "                                            \"reg\": reg,\n",
    "                                        }\n",
    "                                        dataflow_perumations.append(permutation)\n",
    "    return dataflow_perumations\n",
    "\n",
    "# generate all the possible factor permutations for a specific rank (ie, M, N, or K)\n",
    "def get_factor_permutations():\n",
    "    factor_permutations = []\n",
    "    iact_spad_depth = 16 # M, K\n",
    "    weight_spad_depth = 192 # K, N\n",
    "    psum_spad_depth = 32 # M, N\n",
    "\n",
    "    max_K = int(max(math.log2(weight_spad_depth), math.log2(iact_spad_depth)))\n",
    "    max_M = int(max(math.log2(psum_spad_depth), math.log2(iact_spad_depth)))\n",
    "    max_N = int(max(math.log2(weight_spad_depth), math.log2(psum_spad_depth)))     \n",
    "    \n",
    "    for DRAM_M in [2**i for i in range(int(math.log2(matrix_size)) + 1)]:\n",
    "        for DRAM_N in [2**i for i in range(int(math.log2(matrix_size)) + 1)]:\n",
    "                for DRAM_K in [2**i for i in range(int(math.log2(matrix_size)) + 1)]:\n",
    "\n",
    "                    for iact_spad_M in [2**i for i in range(max_M + 1)]:\n",
    "                        for iact_spad_K in [2**j for j in range(max_K + 1)]:\n",
    "                            iact_spad_N = 1  # Inputs → M & K only\n",
    "                    \n",
    "                            for weight_spad_K in [2**i for i in range(max_K + 1)]:\n",
    "                                for weight_spad_N in [2**j for j in range(max_N + 1)]:\n",
    "                                    weight_spad_M = 1  # Weights → K & N only\n",
    "                    \n",
    "                                    for psum_M in [2**i for i in range(max_M + 1)]:\n",
    "                                        for psum_N in [2**j for j in range(max_N + 1)]:\n",
    "                                            psum_K = 1  # Outputs → M & N only\n",
    "                                            # tile size must fit into the iact_spad, weight_spad, and psum_spad\n",
    "                                            if not (\n",
    "                                                ((iact_spad_M * weight_spad_M * psum_M) * (iact_spad_K * weight_spad_K * psum_K) <=  iact_spad_depth) and\n",
    "                                                ((iact_spad_K * weight_spad_K * psum_K) * (iact_spad_N * weight_spad_N * psum_N) <=  weight_spad_depth) and\n",
    "                                                ((iact_spad_M * weight_spad_M * psum_M) * (iact_spad_N * weight_spad_N * psum_N) <=  psum_spad_depth)\n",
    "                                            ):\n",
    "                                                break\n",
    "\n",
    "                                            if ((DRAM_M * iact_spad_M * weight_spad_M * psum_M == matrix_size) and\n",
    "                                                (DRAM_N * iact_spad_N * weight_spad_N * psum_N == matrix_size) and\n",
    "                                                (DRAM_K * iact_spad_K * weight_spad_K * psum_K == matrix_size)):\n",
    "                                                permuation = {\n",
    "                                                    \"DRAM_M\": DRAM_M,\n",
    "                                                    \"DRAM_N\": DRAM_N,\n",
    "                                                    \"DRAM_K\": DRAM_K,\n",
    "\n",
    "                                                    \"ClusterArray_M\": 1,\n",
    "                                                    \"ClusterArray_N\": 1,\n",
    "                                                    \"ClusterArray_K\": 1,\n",
    "\n",
    "                                                    # \"GLB_Cluster_M\": 1,\n",
    "                                                    # \"GLB_Cluster_N\": 1,\n",
    "                                                    # \"GLB_Cluster_K\": 1,\n",
    "\n",
    "                                                    # \"glb_M\": 4,\n",
    "                                                    # \"glb_N\": 4,\n",
    "                                                    # \"glb_K\": 4,\n",
    "\n",
    "                                                    \"PE_Cluster_M\": 1,\n",
    "                                                    \"PE_Cluster_N\": 1,\n",
    "                                                    \"PE_Cluster_K\": 1,\n",
    "\n",
    "                                                    \"iact_spad_M\": iact_spad_M,\n",
    "                                                    \"iact_spad_N\": iact_spad_N,\n",
    "                                                    \"iact_spad_K\": iact_spad_K,\n",
    "\n",
    "                                                    \"weight_spad_M\": weight_spad_M,\n",
    "                                                    \"weight_spad_N\": weight_spad_N,\n",
    "                                                    \"weight_spad_K\": weight_spad_K,\n",
    "\n",
    "                                                    \"psum_M\": psum_M,\n",
    "                                                    \"psum_N\": psum_N,\n",
    "                                                    \"psum_K\": psum_K,\n",
    "\n",
    "                                                    \"reg_M\": 1,\n",
    "                                                    \"reg_N\": 1,\n",
    "                                                    \"reg_K\": 1,\n",
    "                                                }\n",
    "                                                factor_permutations.append(permuation) \n",
    "    return factor_permutations\n",
    "\n",
    "def update_factor_permutation_helper(factor_permutation, component, max_spatial, factor):\n",
    "    # factor is M, N, or K\n",
    "    # component is PE_Cluster or ClusterArray\n",
    "    factor_permutation[f\"{component}_{factor}\"] = max_spatial\n",
    "    for component in [\"DRAM\", \"iact_spad\", \"weight_spad\", \"psum\", \"reg\"]:\n",
    "        curr_component_factor = factor_permutation[f\"{component}_{factor}\"]\n",
    "        if curr_component_factor >= max_spatial:\n",
    "            factor_permutation[f\"{component}_{factor}\"] = curr_component_factor // max_spatial\n",
    "            break\n",
    "    \n",
    "def update_factor_permutation(factor_permutation, dataflow_permutation):\n",
    "    # Cluster Array is 8x2\n",
    "    # PE_Cluster is 4x4\n",
    "    possible_max_ClusterArray = [(8, 2)]\n",
    "    possible_max_PE_Cluster = [(4, 4)]\n",
    "    max_ClusterArray = random.choice(possible_max_ClusterArray)\n",
    "    max_PE_Cluster = random.choice(possible_max_PE_Cluster)\n",
    "    \n",
    "    max_ClusterArray_X = max_ClusterArray[0]\n",
    "    max_ClusterArray_Y = max_ClusterArray[1]\n",
    "    max_PE_Cluster_X = max_PE_Cluster[1]\n",
    "    max_PE_Cluster_Y = max_PE_Cluster[1]\n",
    "    \n",
    "    PE_Cluster_dataflow = dataflow_permutation[\"PE_Cluster\"]\n",
    "    PE_Cluster_dataflow_X = PE_Cluster_dataflow[0]\n",
    "    PE_Cluster_dataflow_Y = PE_Cluster_dataflow[1]\n",
    "\n",
    "    update_factor_permutation_helper(factor_permutation, \"PE_Cluster\", max_PE_Cluster_X, PE_Cluster_dataflow_X)\n",
    "    update_factor_permutation_helper(factor_permutation, \"PE_Cluster\", max_PE_Cluster_Y, PE_Cluster_dataflow_Y)\n",
    "\n",
    "    ClusterArray_dataflow = dataflow_permutation[\"ClusterArray\"]\n",
    "    ClusterArray_dataflow_X = ClusterArray_dataflow[0]\n",
    "    ClusterArray_dataflow_Y = ClusterArray_dataflow[1]\n",
    "\n",
    "    update_factor_permutation_helper(factor_permutation, \"ClusterArray\", max_ClusterArray_X, ClusterArray_dataflow_X)\n",
    "    update_factor_permutation_helper(factor_permutation, \"ClusterArray\", max_ClusterArray_Y, ClusterArray_dataflow_Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fda549d-8e7b-4886-84a0-a833b27cb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataflow_permutations = get_dataflow_permutations()\n",
    "factor_permutations = get_factor_permutations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97960b1-6bd4-4141-93ff-3bb871a05d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_config(config):\n",
    "    return tuple((k, tuple(v) if isinstance(v, list) else v) for k, v in config.items())\n",
    "\n",
    "def sample_config(dataflow_permutations, factor_permutations):\n",
    "    factor_permutation = random.choice(factor_permutations)\n",
    "    dataflow_permutation = random.choice(dataflow_permutations)\n",
    "\n",
    "    update_factor_permutation(factor_permutation, dataflow_permutation)\n",
    "    \n",
    "    config = dict(\n",
    "        matrix_size_M_dim=matrix_size,\n",
    "        matrix_size_K_dim=matrix_size,\n",
    "        matrix_size_N_dim=matrix_size,\n",
    "        \n",
    "        DRAM_factor_M=factor_permutation[\"DRAM_M\"],\n",
    "        DRAM_factor_N=factor_permutation[\"DRAM_N\"],\n",
    "        DRAM_factor_K=factor_permutation[\"DRAM_K\"],\n",
    "        DRAM_permutation=dataflow_permutation[\"DRAM\"],\n",
    "    \n",
    "        ClusterArray_factor_M=factor_permutation[\"ClusterArray_M\"],\n",
    "        ClusterArray_factor_N=factor_permutation[\"ClusterArray_N\"],\n",
    "        ClusterArray_factor_K=factor_permutation[\"ClusterArray_K\"],\n",
    "        ClusterArray_permutation=dataflow_permutation[\"ClusterArray\"],\n",
    "    \n",
    "        # GLB_Cluster_factor_M=factor_permutation[\"GLB_Cluster_M\"],\n",
    "        # GLB_Cluster_factor_N=factor_permutation[\"GLB_Cluster_N\"],\n",
    "        # GLB_Cluster_factor_K=factor_permutation[\"GLB_Cluster_K\"],\n",
    "        # GLB_Cluster_permutation=dataflow_permutation[\"GLB_Cluster\"],\n",
    "    \n",
    "        # glb_factor_M=factor_permutation[\"glb_M\"],\n",
    "        # glb_factor_N=factor_permutation[\"glb_N\"],\n",
    "        # glb_factor_K=factor_permutation[\"glb_K\"],\n",
    "        # glb_permutation=dataflow_permutation[\"glb\"],\n",
    "    \n",
    "        PE_Cluster_factor_M=factor_permutation[\"PE_Cluster_M\"],\n",
    "        PE_Cluster_factor_N=factor_permutation[\"PE_Cluster_N\"],\n",
    "        PE_Cluster_factor_K=factor_permutation[\"PE_Cluster_K\"],\n",
    "        PE_Cluster_permutation=dataflow_permutation[\"PE_Cluster\"],\n",
    "    \n",
    "        iact_spad_factor_M=factor_permutation[\"iact_spad_M\"],\n",
    "        iact_spad_factor_N=factor_permutation[\"iact_spad_N\"],\n",
    "        iact_spad_factor_K=factor_permutation[\"iact_spad_K\"],\n",
    "        iact_spad_permutation=dataflow_permutation[\"iact_spad\"],\n",
    "    \n",
    "        weight_spad_factor_M=factor_permutation[\"weight_spad_M\"],\n",
    "        weight_spad_factor_N=factor_permutation[\"weight_spad_N\"],\n",
    "        weight_spad_factor_K=factor_permutation[\"weight_spad_K\"],\n",
    "        weight_spad_permutation=dataflow_permutation[\"weight_spad\"],\n",
    "    \n",
    "        psum_factor_M=factor_permutation[\"psum_M\"],\n",
    "        psum_factor_N=factor_permutation[\"psum_N\"],\n",
    "        psum_factor_K=factor_permutation[\"psum_K\"],\n",
    "        psum_permutation=dataflow_permutation[\"psum\"],\n",
    "    \n",
    "        reg_factor_M=factor_permutation[\"reg_M\"],\n",
    "        reg_factor_N=factor_permutation[\"reg_N\"],\n",
    "        reg_factor_K=factor_permutation[\"reg_K\"],\n",
    "        reg_permutation=dataflow_permutation[\"reg\"],\n",
    "    \n",
    "        density_weights=1,\n",
    "        density_inputs=1,\n",
    "\n",
    "        pe_meshX=4,\n",
    "        pe_meshY=4,\n",
    "    )\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b301d-eac9-48eb-9051-9d9dd651bc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_config(config, sparse_opt=None):\n",
    "    if sparse_opt == None:\n",
    "        sparse_opt = 'designs/baseline/baseline_sparse_opt.yaml'\n",
    "\n",
    "    out = run_timeloop_model(\n",
    "        config,\n",
    "        problem='designs/baseline/baseline_problem.yaml',\n",
    "        mapping='designs/baseline/baseline_mapping.yaml',\n",
    "        sparse_optimizations=sparse_opt, \n",
    "    )\n",
    "    stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "    return stats\n",
    "\n",
    "\n",
    "def update_opt_config_and_curr_opt(config, attributes, opt_config, curr_opt, sparse_opt=None):\n",
    "    q1_config, q2_config, q4_config = config.copy(), config.copy(), config.copy()\n",
    "    q1_config['density_inputs'] = 0.5\n",
    "    q2_config['density_inputs'] = 0.001\n",
    "    q4_config['density_inputs'] = 1.0\n",
    "\n",
    "    q1_stats = evaluate_config(q1_config, sparse_opt)\n",
    "    q2_stats = evaluate_config(q2_config, sparse_opt)\n",
    "    q4_stats = evaluate_config(q4_config, sparse_opt)\n",
    "    \n",
    "    all_stats = [q1_stats, q2_stats, q1_stats, q4_stats]\n",
    "    \n",
    "    parsed_runs = [parse_timeloop_stats(stats) for stats in all_stats]\n",
    "    combined_stats = aggregate_timeloop_runs(parsed_runs)\n",
    "\n",
    "    for attr in attributes: \n",
    "        if attr in ['total_energy_uJ', 'computes_per_cycle']:\n",
    "            val = combined_stats[attr]\n",
    "        elif attr == 'utilization_percent': \n",
    "            val = combined_stats[attr]['overall']\n",
    "        elif attr == 'memory_traffic': \n",
    "            val = sum(combined_stats[attr].values())\n",
    "        else: \n",
    "            raise ValueError(f\"{attr} not a valid attribute.\")\n",
    "\n",
    "        if attr in ['total_energy_uJ', 'memory_traffic']: \n",
    "            if val < curr_opt[attr]:\n",
    "                opt_config[attr] = config\n",
    "                curr_opt[attr] = val\n",
    "        elif attr in ['utilization_percent', 'computes_per_cycle']: \n",
    "            if val > curr_opt[attr]: \n",
    "                opt_config[attr] = config\n",
    "                curr_opt[attr] = val\n",
    "\n",
    "\n",
    "def get_initial_opt_config_and_curr_opt(attributes):\n",
    "    curr_opt = {}\n",
    "    for attr in attributes: \n",
    "        if attr in ['total_energy_uJ', 'memory_traffic']: \n",
    "            curr_opt[attr] = float('inf')\n",
    "        elif attr in ['utilization_percent', 'computes_per_cycle']: \n",
    "            curr_opt[attr] = -float('inf')\n",
    "        else: \n",
    "            raise ValueError(f\"Unexpected Attribute {attr}\")\n",
    "            \n",
    "    opt_config =  {attr: None for attr in attributes}\n",
    "    return opt_config, curr_opt\n",
    "    \n",
    "\n",
    "def get_min_config_attention(attributes, num_of_random_samples = 1, default_config=None):\n",
    "    print(f\"optimizing over: {attributes}, num_of_random_samples: {num_of_random_samples}\")\n",
    "    visited = set()\n",
    "                \n",
    "    opt_config, curr_opt =  get_initial_opt_config_and_curr_opt(attributes)\n",
    "    \n",
    "    # uses random sampling instead of a for loop\n",
    "    for sample in range(num_of_random_samples):\n",
    "        # print(\"\\nsample: \", sample, \"curr_min\", curr_min)\n",
    "        \n",
    "        config = sample_config(dataflow_permutations, factor_permutations)\n",
    "        while hash_config(config) in visited:\n",
    "            config = sample_config(dataflow_permutations, factor_permutations)\n",
    "        visited.add(hash_config(config))\n",
    "        # print(\"config: \", config)\n",
    "        try: \n",
    "            update_opt_config_and_curr_opt(config, attributes, opt_config, curr_opt)\n",
    "        except: \n",
    "            continue\n",
    "\n",
    "    return opt_config, curr_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42811cd4-867c-4534-a46a-efe2ee32b649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_of_random_samples = 1\n",
    "attributes = ['total_energy_uJ', 'utilization_percent', 'computes_per_cycle', 'memory_traffic']\n",
    "min_config, curr_min = get_min_config_attention(attributes, num_of_random_samples)\n",
    "print(\"==================OUTPUT==================\")\n",
    "print(\"min_config: \", min_config)\n",
    "print(\"curr_min: \", curr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f5dc0-e213-4593-aa5a-3727935245f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data\"\n",
    "name = \"saniya_1\" #Change\n",
    "os.makedirs(f\"{folder}\", exist_ok=True)\n",
    "\n",
    "with open(f\"{folder}/200_min_config_{name}\", \"w\") as f:\n",
    "    json.dump(min_config, f, indent=2)\n",
    "with open(f\"{folder}/200_curr_min_{name}\", \"w\") as f:\n",
    "    json.dump(curr_min, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7023c-ad37-486b-8c99-0612892979bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !timeloop model ./output_dir/parsed-processed-input.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98adc084-2656-4e30-850a-3b415157cdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
