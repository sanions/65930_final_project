{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f77928a-de22-48f2-8160-09ceaab41d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loaders import *\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335265f4-6e46-4548-a0dc-584caec31243",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = 4096\n",
    "\n",
    "dataflow_permuations = [['M', 'N', 'K'], ['M', 'K', 'N'], ['N', 'K', 'M'], ['N', 'M', 'K'], ['K', 'N', 'M'], ['K', 'M', 'N']]\n",
    "'''\n",
    "6 different dataflow permutations\n",
    "9 components for dataflow\n",
    "= 6^9 = 10077696 possible combinations\n",
    "'''\n",
    "# generate all the data flow permuations\n",
    "def get_dataflow_permutations():\n",
    "    dataflow_perumations = []\n",
    "    \n",
    "    for DRAM in dataflow_permuations:\n",
    "        for ClusterArray in dataflow_permuations:\n",
    "            for GLB_Cluster in dataflow_permuations:\n",
    "                for glb in dataflow_permuations:\n",
    "                    for PE_Cluster in dataflow_permuations:\n",
    "                        for iact_spad in dataflow_permuations:\n",
    "                            for weight_spad in dataflow_permuations:\n",
    "                                for psum in dataflow_permuations:\n",
    "                                    for reg in dataflow_permuations:\n",
    "                                        permutation = {\n",
    "                                            \"DRAM\": DRAM,\n",
    "                                            \"ClusterArray\": ClusterArray,\n",
    "                                            \"GLB_Cluster\": GLB_Cluster,\n",
    "                                            \"glb\": glb,\n",
    "                                            \"PE_Cluster\": PE_Cluster,\n",
    "                                            \"iact_spad\": iact_spad,\n",
    "                                            \"weight_spad\": weight_spad,\n",
    "                                            \"psum\": psum,\n",
    "                                            \"reg\": reg,\n",
    "                                        }\n",
    "                                        dataflow_perumations.append(permutation)\n",
    "    return dataflow_perumations\n",
    "\n",
    "# generate all the possible factor permutations for a specific rank (ie, M, N, or K)\n",
    "def get_factor_permutations():\n",
    "    factor_permutations = []\n",
    "    \n",
    "    for DRAM in [2**i for i in range(int(math.log2(matrix_size)) + 1)]:\n",
    "        curr_prod1 = DRAM\n",
    "        for ClusterArray in [2**i for i in range(int(math.log2(matrix_size // curr_prod1)) + 1)]:\n",
    "            curr_prod2 = curr_prod1 * ClusterArray\n",
    "            for GLB_Cluster in [2**i for i in range(int(math.log2(matrix_size // curr_prod2)) + 1)]:\n",
    "                curr_prod3 = curr_prod2 * GLB_Cluster\n",
    "                for glb in [2**i for i in range(int(math.log2(matrix_size // curr_prod3)) + 1)]:\n",
    "                    curr_prod4 = curr_prod3 * glb\n",
    "                    for PE_Cluster in [2**i for i in range(int(math.log2(matrix_size // curr_prod4)) + 1)]:\n",
    "                        curr_prod5 = curr_prod4 * PE_Cluster\n",
    "                        for iact_spad in [2**i for i in range(int(math.log2(matrix_size // curr_prod5)) + 1)]:\n",
    "                            curr_prod6 = curr_prod5 * iact_spad\n",
    "                            for weight_spad in [2**i for i in range(int(math.log2(matrix_size // curr_prod6)) + 1)]:\n",
    "                                curr_prod7 = curr_prod6 * weight_spad\n",
    "                                for psum in [2**i for i in range(int(math.log2(matrix_size // curr_prod7)) + 1)]:\n",
    "                                    curr_prod8 = curr_prod7 * psum\n",
    "                                    for reg in [2**i for i in range(int(math.log2(matrix_size // curr_prod8)) + 1)]:\n",
    "                                        final_prod = curr_prod8 * reg\n",
    "                                        if final_prod == matrix_size:\n",
    "                                            permuation = {\n",
    "                                                \"DRAM\": DRAM,\n",
    "                                                \"ClusterArray\": ClusterArray,\n",
    "                                                \"GLB_Cluster\": GLB_Cluster,\n",
    "                                                \"glb\": glb,\n",
    "                                                \"PE_Cluster\": PE_Cluster,\n",
    "                                                \"iact_spad\": iact_spad,\n",
    "                                                \"weight_spad\": weight_spad,\n",
    "                                                \"psum\": psum,\n",
    "                                                \"reg\": reg,\n",
    "                                            }\n",
    "                                            factor_permutations.append(permuation)\n",
    "                                            \n",
    "    return factor_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fda549d-8e7b-4886-84a0-a833b27cb77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataflow_permutations = get_dataflow_permutations()\n",
    "factor_permutations = get_factor_permutations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e97960b1-6bd4-4141-93ff-3bb871a05d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_config(config):\n",
    "    print(config)\n",
    "    out = run_timeloop_model(\n",
    "        config,\n",
    "        problem='designs/baseline/baseline_problem.yaml',\n",
    "        mapping='designs/baseline/baseline_mapping.yaml',\n",
    "        sparse_optimizations='designs/baseline/baseline_sparse_opt.yaml', \n",
    "    )\n",
    "    stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "    print(stats)\n",
    "\n",
    "def hash_config(config):\n",
    "    return tuple((k, tuple(v) if isinstance(v, list) else v) for k, v in config.items())\n",
    "\n",
    "def sample_config(dataflow_permutations, factor_permutations):\n",
    "    M_factor_permutation = random.choice(factor_permutations)\n",
    "    N_factor_permutation = random.choice(factor_permutations)\n",
    "    K_factor_permutation = random.choice(factor_permutations)\n",
    "    \n",
    "    dataflow_permutation = random.choice(dataflow_permutations)\n",
    "    \n",
    "    config = dict(\n",
    "        matrix_size_M_dim=matrix_size,\n",
    "        matrix_size_K_dim=matrix_size,\n",
    "        matrix_size_N_dim=matrix_size,\n",
    "        \n",
    "        DRAM_factor_M=M_factor_permutation[\"DRAM\"],\n",
    "        DRAM_factor_N=N_factor_permutation[\"DRAM\"],\n",
    "        DRAM_factor_K=K_factor_permutation[\"DRAM\"],\n",
    "        DRAM_permutation=dataflow_permutation[\"DRAM\"],\n",
    "    \n",
    "        ClusterArray_factor_M=M_factor_permutation[\"ClusterArray\"],\n",
    "        ClusterArray_factor_N=N_factor_permutation[\"ClusterArray\"],\n",
    "        ClusterArray_factor_K=K_factor_permutation[\"ClusterArray\"],\n",
    "        ClusterArray_permutation=dataflow_permutation[\"ClusterArray\"],\n",
    "    \n",
    "        GLB_Cluster_factor_M=M_factor_permutation[\"GLB_Cluster\"],\n",
    "        GLB_Cluster_factor_N=N_factor_permutation[\"GLB_Cluster\"],\n",
    "        GLB_Cluster_factor_K=K_factor_permutation[\"GLB_Cluster\"],\n",
    "        GLB_Cluster_permutation=dataflow_permutation[\"GLB_Cluster\"],\n",
    "    \n",
    "        glb_factor_M=M_factor_permutation[\"glb\"],\n",
    "        glb_factor_N=N_factor_permutation[\"glb\"],\n",
    "        glb_factor_K=K_factor_permutation[\"glb\"],\n",
    "        glb_permutation=dataflow_permutation[\"glb\"],\n",
    "    \n",
    "        PE_Cluster_factor_M=M_factor_permutation[\"PE_Cluster\"],\n",
    "        PE_Cluster_factor_N=N_factor_permutation[\"PE_Cluster\"],\n",
    "        PE_Cluster_factor_K=K_factor_permutation[\"PE_Cluster\"],\n",
    "        PE_Cluster_permutation=dataflow_permutation[\"PE_Cluster\"],\n",
    "    \n",
    "        iact_spad_factor_M=M_factor_permutation[\"iact_spad\"],\n",
    "        iact_spad_factor_N=N_factor_permutation[\"iact_spad\"],\n",
    "        iact_spad_factor_K=K_factor_permutation[\"iact_spad\"],\n",
    "        iact_spad_permutation=dataflow_permutation[\"iact_spad\"],\n",
    "    \n",
    "        weight_spad_factor_M=M_factor_permutation[\"weight_spad\"],\n",
    "        weight_spad_factor_N=N_factor_permutation[\"weight_spad\"],\n",
    "        weight_spad_factor_K=K_factor_permutation[\"weight_spad\"],\n",
    "        weight_spad_permutation=dataflow_permutation[\"weight_spad\"],\n",
    "    \n",
    "        psum_factor_M=M_factor_permutation[\"psum\"],\n",
    "        psum_factor_N=N_factor_permutation[\"psum\"],\n",
    "        psum_factor_K=K_factor_permutation[\"psum\"],\n",
    "        psum_permutation=dataflow_permutation[\"psum\"],\n",
    "    \n",
    "        reg_factor_M=M_factor_permutation[\"reg\"],\n",
    "        reg_factor_N=N_factor_permutation[\"reg\"],\n",
    "        reg_factor_K=K_factor_permutation[\"reg\"],\n",
    "        reg_permutation=dataflow_permutation[\"reg\"],\n",
    "    \n",
    "        density_weights=1,\n",
    "        density_inputs=1\n",
    "    )\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f68b301d-eac9-48eb-9051-9d9dd651bc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matrix_size_M_dim': 4096, 'matrix_size_K_dim': 4096, 'matrix_size_N_dim': 4096, 'DRAM_factor_M': 4, 'DRAM_factor_N': 4, 'DRAM_factor_K': 8, 'DRAM_permutation': ['K', 'M', 'N'], 'ClusterArray_factor_M': 8, 'ClusterArray_factor_N': 1, 'ClusterArray_factor_K': 4, 'ClusterArray_permutation': ['K', 'N', 'M'], 'GLB_Cluster_factor_M': 1, 'GLB_Cluster_factor_N': 2, 'GLB_Cluster_factor_K': 1, 'GLB_Cluster_permutation': ['N', 'M', 'K'], 'glb_factor_M': 4, 'glb_factor_N': 8, 'glb_factor_K': 8, 'glb_permutation': ['K', 'N', 'M'], 'PE_Cluster_factor_M': 1, 'PE_Cluster_factor_N': 1, 'PE_Cluster_factor_K': 2, 'PE_Cluster_permutation': ['N', 'M', 'K'], 'iact_spad_factor_M': 1, 'iact_spad_factor_N': 4, 'iact_spad_factor_K': 1, 'iact_spad_permutation': ['K', 'M', 'N'], 'weight_spad_factor_M': 4, 'weight_spad_factor_N': 4, 'weight_spad_factor_K': 8, 'weight_spad_permutation': ['K', 'M', 'N'], 'psum_factor_M': 8, 'psum_factor_N': 4, 'psum_factor_K': 1, 'psum_permutation': ['M', 'K', 'N'], 'reg_factor_M': 1, 'reg_factor_N': 1, 'reg_factor_K': 1, 'reg_permutation': ['N', 'M', 'K'], 'density_weights': 1, 'density_inputs': 1}\n",
      "[INFO] 2025-04-28 21:53:07,633 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "\n\n========================================================================================================================\nTimeloop model failed with return code 1. Please check the output files in ./output_dir for more information. To debug, you can edit the file:\n\t./output_dir/parsed-processed-input.yaml\nand run \n\ttimeloop model ./output_dir/parsed-processed-input.yaml\nto see the error. If you're running the mapper and Timeloop can't find a vaild mapping, try setting 'diagnostics: true' in the mapper input specification.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/final_project/loaders.py:54\u001b[0m, in \u001b[0;36mrun_timeloop_model\u001b[0;34m(jinja_parse_data, alt_top, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./output_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/backend_calls.py:268\u001b[0m, in \u001b[0;36mcall_model\u001b[0;34m(specification, output_dir, environment, extra_input_files, dump_intermediate_to, log_to, extra_args, return_proc)\u001b[0m\n\u001b[1;32m    264\u001b[0m input_paths, output_dir \u001b[38;5;241m=\u001b[39m _pre_call(\n\u001b[1;32m    265\u001b[0m     specification, output_dir, extra_input_files, for_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    266\u001b[0m )\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeloop-model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdump_intermediate_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdump_intermediate_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfor_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytimeloop/timeloopfe/common/backend_calls.py:184\u001b[0m, in \u001b[0;36m_parse_output\u001b[0;34m(specification, output_dir, result, for_model)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(errmsg)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n\n========================================================================================================================\nTimeloop model failed with return code 1. Please check the output files in ./output_dir for more information. To debug, you can edit the file:\n\t./output_dir/parsed-processed-input.yaml\nand run \n\ttl model ./output_dir/parsed-processed-input.yaml\nto see the error. If you're running the mapper and Timeloop can't find a vaild mapping, try setting 'diagnostics: true' in the mapper input specification.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m hash_config(config) \u001b[38;5;129;01min\u001b[39;00m visited:\n\u001b[1;32m      9\u001b[0m     config \u001b[38;5;241m=\u001b[39m sample_config(dataflow_permutations, factor_permutations)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mevaluate_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m visited\u001b[38;5;241m.\u001b[39madd(hash_config(config))\n",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m, in \u001b[0;36mevaluate_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_config\u001b[39m(config):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(config)\n\u001b[0;32m----> 3\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun_timeloop_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesigns/baseline/baseline_problem.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesigns/baseline/baseline_mapping.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse_optimizations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesigns/baseline/baseline_sparse_opt.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output_dir/timeloop-model.stats.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(stats)\n",
      "File \u001b[0;32m~/final_project/loaders.py:56\u001b[0m, in \u001b[0;36mrun_timeloop_model\u001b[0;34m(jinja_parse_data, alt_top, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tl\u001b[38;5;241m.\u001b[39mcall_model(spec, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtl model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeloop model\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mException\u001b[0m: \n\n========================================================================================================================\nTimeloop model failed with return code 1. Please check the output files in ./output_dir for more information. To debug, you can edit the file:\n\t./output_dir/parsed-processed-input.yaml\nand run \n\ttimeloop model ./output_dir/parsed-processed-input.yaml\nto see the error. If you're running the mapper and Timeloop can't find a vaild mapping, try setting 'diagnostics: true' in the mapper input specification."
     ]
    }
   ],
   "source": [
    "num_of_random_samples = 2\n",
    "visited = set()\n",
    "\n",
    "# uses random sampling instead of a for loop\n",
    "for sample in range(num_of_random_samples):\n",
    "    # sample\n",
    "    config = sample_config(dataflow_permutations, factor_permutations)\n",
    "    while hash_config(config) in visited:\n",
    "        config = sample_config(dataflow_permutations, factor_permutations)\n",
    "    evaluate_config(config)\n",
    "\n",
    "    visited.add(hash_config(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77a7023c-ad37-486b-8c99-0612892979bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running apps: model\n",
      "Found parsed-processed-input.yaml in input files. Running Timeloop without parsing or processing steps. If this is not the intended behavior, please name the input files differently.\n",
      "input file: /home/workspace/final_project/output_dir/parsed-processed-input.yaml\n",
      "execute:/usr/local/bin/accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml --oprefix timeloop-model. -o ./ > timeloop-model.accelergy.log 2>&1\n",
      "Warning: DRAM: adjust representation format word bits from 7 to 8 to avoid storage fragmentation.\n",
      "Warning: weight_spad: adjust representation format word bits from 7 to 8 to avoid storage fragmentation.\n",
      "WARNING: parsing mapping: permutation not found for level: glb (temporal)\n",
      "WARNING: parsing mapping: permutation contains insufficient dimensions at level: glb (temporal), padding with arbitrary order.\n",
      "WARNING: parsing mapping: factors not found for level: glb (temporal)\n",
      "WARNING: parsing mapping: factors not provided for all dimensions at level: glb (temporal), setting to 1.\n",
      "ERROR: parsing mapping: product of all factors of dimension N is 2048, which is not equal to the dimension size of the workload 4096.\n"
     ]
    }
   ],
   "source": [
    "!timeloop model ./output_dir/parsed-processed-input.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c6ceb-734b-4fc5-99f9-dbeb579ac167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
